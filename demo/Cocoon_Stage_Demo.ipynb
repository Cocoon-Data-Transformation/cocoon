{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxJasA99aYfS"
      },
      "source": [
        "# **Cocoon: Organize your Data Warehouse, ready for analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Vh5gYMb_6u"
      },
      "source": [
        "### **For the demo, you Need...**\n",
        "\n",
        "1. LLM API (cost is typically <50 cents per table)\n",
        "2. Data Warehouse Con (e.g., Snowflake/DuckDB...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO5wBZ0eb8a0"
      },
      "outputs": [],
      "source": [
        "! pip install cocoon_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_uRoPcrW6pJ"
      },
      "outputs": [],
      "source": [
        "from cocoon_data import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSWSHgdsdeLw",
        "outputId": "b2b26b08-a6f3-4e59-9028-9c1bd4829253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "orders.csv downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "#@title  Download example table (skip this step if you have your own table)\n",
        "import requests\n",
        "\n",
        "files = {\n",
        "    \"orders.csv\": \"https://raw.githubusercontent.com/Cocoon-Data-Transformation/cocoon/main/files/orders.csv\",\n",
        "}\n",
        "\n",
        "# Loop through the files dictionary\n",
        "for file_name, url in files.items():\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Open file in binary write mode\n",
        "        with open(file_name, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"{file_name} downloaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Failed to download {file_name}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqW-mSHsdeTV",
        "outputId": "e7c5ee67-e9bb-4663-84e7-4b7bfd0e2f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "#@title Provide your LLM API (prefer claude 3.5 sonnet)\n",
        "\n",
        "# if you use Anthropic\n",
        "openai.api_type ='Anthropic'\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"\"\n",
        "cocoon_llm_setting['claude_model'] = \"claude-3-5-sonnet-20240620\"\n",
        "\n",
        "# # if you use Vertex AI\n",
        "# openai.api_type = 'AnthropicVertex'\n",
        "# cocoon_llm_setting['vertex_region'] = \"us-east5\"\n",
        "# cocoon_llm_setting['vertex_project_id'] = \"\"\n",
        "# cocoon_llm_setting['vertex_model'] = \"claude-3-5-sonnet@20240620\"\n",
        "\n",
        "# # if you use Bedrock\n",
        "# openai.api_type = 'AnthropicBedrock'\n",
        "# cocoon_llm_setting['aws_access_key'] = \"\"\n",
        "# cocoon_llm_setting['aws_secret_key'] = \"\"\n",
        "# cocoon_llm_setting['aws_region'] = \"us-east-1\"\n",
        "# cocoon_llm_setting['aws_model'] = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
        "\n",
        "# # if you use Open AI\n",
        "# openai.api_key  = ''\n",
        "# cocoon_llm_setting['openai_model'] = \"gpt-4-turbo\"\n",
        "\n",
        "# test if LLM works\n",
        "test_message = \"hello\"\n",
        "messages = [{\"role\": \"user\", \"content\": test_message}]\n",
        "response = call_llm_chat(messages, temperature=0.1, top_p=0.1)\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNNJuV02gwU8",
        "outputId": "0b68eba8-640f-4a10-e132-59f332d8e406"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<duckdb.duckdb.DuckDBPyConnection at 0x7e35da0c8270>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Provide Data Warehouse Con\n",
        "\n",
        "# In-mem duckdb loads the df\n",
        "con = duckdb.connect(database=':memory:')\n",
        "df = pd.read_csv(\"orders.csv\")\n",
        "table_name = \"orders\"\n",
        "df.columns = [clean_column_name(col) for col in df.columns]\n",
        "con.register(table_name, df)\n",
        "\n",
        "# # Snowflake\n",
        "# con = snowflake.connector.connect(\n",
        "#     # check out your url: {account}.snowflakecomputing.com\n",
        "#     account=\"\",\n",
        "#     user=\"\",\n",
        "#     password=\"\",\n",
        "#     warehouse=\"\",\n",
        "#     database=\"\",\n",
        "#     schema=\"\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCdGlUQPVxs0"
      },
      "outputs": [],
      "source": [
        "query_widget, cocoon_workflow = create_cocoon_workflow(con)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_3kqZggd3Z0"
      },
      "outputs": [],
      "source": [
        "query_widget.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3qATb29ed4V"
      },
      "outputs": [],
      "source": [
        "# Note that Cocoon currently can't change the previous step\n",
        "# You need to rerun the 'create_cocoon_workflow(con)' above ðŸ‘†\n",
        "cocoon_workflow.start()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
