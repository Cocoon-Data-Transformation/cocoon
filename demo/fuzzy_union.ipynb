{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxJasA99aYfS"
      },
      "source": [
        "# **Cocoon: Fuzzy Union, Table Transformation, Common Data Model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Vh5gYMb_6u"
      },
      "source": [
        "## **You Need...**\n",
        "\n",
        "1. LLM API (only support openai for now; please send a feature request for other API)\n",
        "2. Data Warehouse Con (Snowflake/DuckDB/csv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO5wBZ0eb8a0"
      },
      "outputs": [],
      "source": [
        "! pip install cocoon_data==0.1.107"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_uRoPcrW6pJ"
      },
      "outputs": [],
      "source": [
        "from cocoon_data import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSWSHgdsdeLw"
      },
      "outputs": [],
      "source": [
        "#@title  Download example table (skip this step if you have your own table)\n",
        "import requests\n",
        "\n",
        "files = {\n",
        "    \"person_example.csv\": \"https://raw.githubusercontent.com/Cocoon-Data-Transformation/cocoon/main/files/person_example.csv\",\n",
        "    \"patients.csv\": \"https://raw.githubusercontent.com/Cocoon-Data-Transformation/cocoon/main/files/patients.csv\",\n",
        "}\n",
        "\n",
        "# Loop through the files dictionary\n",
        "for file_name, url in files.items():\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Open file in binary write mode\n",
        "        with open(file_name, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"{file_name} downloaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Failed to download {file_name}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqW-mSHsdeTV"
      },
      "outputs": [],
      "source": [
        "#@title Provide your LLM API\n",
        "\n",
        "# if you use Open AI, please ensure GPT-4 is available\n",
        "openai.api_key  = ''\n",
        "\n",
        "# # if you use anthropic, please ensure Claude 3 Opus is available\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"\"\n",
        "# openai.api_type ='claude'\n",
        "\n",
        "# # if you use Vertex AI, please ensure Claude 3 Opus is available\n",
        "# openai.api_type = 'AnthropicVertex'\n",
        "# os.environ['AnthropicVertex_region'] = \"us-east5\"\n",
        "# os.environ['AnthropicVertex_project_id'] = \"\"\n",
        "\n",
        "# test if LLM works\n",
        "test_message = \"hello\"\n",
        "messages = [{\"role\": \"user\", \"content\": test_message}]\n",
        "response = call_llm_chat(messages, temperature=0.1, top_p=0.1)\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNNJuV02gwU8"
      },
      "outputs": [],
      "source": [
        "# @title Provide Data Warehouse Con\n",
        "\n",
        "# In-mem duckdb loads the df\n",
        "con = duckdb.connect(database=':memory:')\n",
        "for csv_file in files:\n",
        "    file_path = f'./{csv_file}'\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    table_name = os.path.basename(file_path).split('.')[0]\n",
        "    table_name = clean_table_name(table_name)\n",
        "\n",
        "    query_widget = QueryWidget(con)\n",
        "    con.register(table_name, df)\n",
        "\n",
        "# # Snowflake: specify the con info and table ame\n",
        "# con = snowflake.connector.connect(\n",
        "#     # check out your url: {account}.snowflakecomputing.com\n",
        "#     account=\"\",\n",
        "#     user=\"\",\n",
        "#     password=\"\",\n",
        "#     warehouse=\"\",\n",
        "#     database=\"\",\n",
        "#     schema=\"\",\n",
        "# )\n",
        "# # Please enter the table to stage/clean\n",
        "# # Make sure it's a table (queries over view can be slow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCdGlUQPVxs0"
      },
      "outputs": [],
      "source": [
        "query_widget, cocoon_workflow = create_cocoon_workflow(con)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_3kqZggd3Z0"
      },
      "outputs": [],
      "source": [
        "query_widget.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3qATb29ed4V"
      },
      "outputs": [],
      "source": [
        "cocoon_workflow.start_workflow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1AHSVNoxluw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
