{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxJasA99aYfS"
      },
      "source": [
        "# **Cocoon: Semantic Data Lineage**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Vh5gYMb_6u"
      },
      "source": [
        "## **You Need...**\n",
        "\n",
        "1. LLM API\n",
        "2. Compiled DBT directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO5wBZ0eb8a0"
      },
      "outputs": [],
      "source": [
        "! pip install cocoon_data==0.1.128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_uRoPcrW6pJ"
      },
      "outputs": [],
      "source": [
        "from cocoon_data import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSWSHgdsdeLw"
      },
      "outputs": [],
      "source": [
        "#@title  Download example dbt project (skip this step if you have your own)\n",
        "import requests\n",
        "import os\n",
        "import base64\n",
        "\n",
        "def url_path_join(*args):\n",
        "    \"\"\"Join path components for URL using forward slashes.\"\"\"\n",
        "    return '/'.join(arg.strip('/') for arg in args)\n",
        "\n",
        "def download_github_directory(repo_owner, repo_name, directory_path, local_path):\n",
        "    # GitHub API endpoint\n",
        "    api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{directory_path}\"\n",
        "\n",
        "    # Send a GET request to the GitHub API\n",
        "    response = requests.get(api_url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Create the local directory if it doesn't exist\n",
        "        os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "        # Parse the JSON response\n",
        "        contents = response.json()\n",
        "\n",
        "        # Loop through each file in the directory\n",
        "        for item in contents:\n",
        "            if item['type'] == 'file':\n",
        "                # Get the file content\n",
        "                file_content = requests.get(item['download_url']).content\n",
        "\n",
        "                # Save the file locally\n",
        "                file_path = os.path.join(local_path, item['name'])\n",
        "                with open(file_path, 'wb') as file:\n",
        "                    file.write(file_content)\n",
        "                print(f\"Downloaded: {file_path}\")\n",
        "            elif item['type'] == 'dir':\n",
        "                # If it's a subdirectory, recursively download its contents\n",
        "                subdir_path = url_path_join(directory_path, item['name'])\n",
        "                local_subdir_path = os.path.join(local_path, item['name'])\n",
        "                download_github_directory(repo_owner, repo_name, subdir_path, local_subdir_path)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve directory contents. Status code: {response.status_code}\")\n",
        "\n",
        "# Usage\n",
        "repo_owner = \"Cocoon-Data-Transformation\"\n",
        "repo_name = \"cocoon\"\n",
        "project_name = \"dbt_amplitude\"\n",
        "directory_path = f\"documentation/dbt_projects/{project_name}\"\n",
        "dbt_directory = os.path.join(\".\", project_name)\n",
        "\n",
        "download_github_directory(repo_owner, repo_name, directory_path, dbt_directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Read your dbt project\n",
        "project_name = \"dbt_amplitude\"\n",
        "dbt_directory = os.path.join(\".\", project_name)\n",
        "# please compile your dbt project and generate docs, as we need the relavant jso\n",
        "# by default, we will read manifest.json and catalog.json from target. But if they are in different paths, please provide:\n",
        "# manifest_path = os.path.join(dbt_path, 'target', 'manifest.json')\n",
        "# catalog_path = os.path.join(dbt_path, 'target', 'catalog.json')\n",
        "\n",
        "# make sure the following variables are available\n",
        "# nodes are a list of model name; edges are a list of edge (from_idx, to_idx) for table lineage; sql_mapping mpas model name to sql; column mapping maps model name to column details\n",
        "nodes, edges, sql_mapping, column_mapping = build_lineage_graph(dbt_directory)\n",
        "# nodes, edges, sql_mapping, column_mapping = build_lineage_graph(dbt_path, manifest_path=manifest_path, catalog_path=catalog_path)\n",
        "\n",
        "image = generate_workflow_image(nodes, edges, format='svg')\n",
        "display(HTML(wrap_image_in_html(image, format='svg')))\n",
        "\n",
        "print(\"Nodes:\")\n",
        "for i, node in enumerate(nodes):\n",
        "    sql_content = sql_mapping.get(node, \"\").replace('\\n', ' ')\n",
        "    columns = column_mapping.get(node, [])\n",
        "    print(f\"{i}: {node}\")\n",
        "    if columns:\n",
        "        print(f\"    Columns: {columns}\")\n",
        "    else:\n",
        "        print(\"    ⚠️ No columns found\")\n",
        "    if sql_content:\n",
        "        print(f\"    SQL Content: {sql_content[:30]}...\")\n",
        "    else:\n",
        "        print(\"    ⚠️ No SQL content found\")\n",
        "\n",
        "print(\"\\nEdges:\")\n",
        "print(edges)"
      ],
      "metadata": {
        "id": "eIqjeYuDF720"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8qIWsaTJkqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqW-mSHsdeTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b6a7ec-536f-4ce7-8562-7265555f089a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.\n"
          ]
        }
      ],
      "source": [
        "#@title Provide your LLM API (prefer claude 3.5 sonnet)\n",
        "\n",
        "# if you use Anthropic\n",
        "cocoon_llm_setting['api_type'] = 'Anthropic'\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-api...\"\n",
        "cocoon_llm_setting['aws_access_key'] = \"claude-3-5-sonnet-20240620\"\n",
        "\n",
        "# if you use Vertex AI\n",
        "# cocoon_llm_setting['api_type'] = 'AnthropicVertex'\n",
        "# cocoon_llm_setting['vertex_region'] = \"us-east5\"\n",
        "# cocoon_llm_setting['vertex_project_id'] = \"\"\n",
        "# cocoon_llm_setting['vertex_model'] = \"claude-3-5-sonnet@20240620\"\n",
        "\n",
        "# if you use Bedrock\n",
        "# cocoon_llm_setting['api_type'] = 'AnthropicBedrock'\n",
        "# cocoon_llm_setting['aws_access_key'] = \"...\"\n",
        "# cocoon_llm_setting['aws_secret_key'] = \"...\"\n",
        "# cocoon_llm_setting['aws_region'] = \"us-east-1\"\n",
        "# cocoon_llm_setting['aws_model'] = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
        "\n",
        "# if you use Open AI\n",
        "# cocoon_llm_setting['api_type'] = \"openai\"\n",
        "# cocoon_llm_setting['api_key'] = \"sk-proj-...\"\n",
        "# cocoon_llm_setting['openai_model'] = \"gpt-4-turbo\"\n",
        "\n",
        "# if you use Azure Open AI\n",
        "# cocoon_llm_setting['api_type'] = \"azure\"\n",
        "# # azure openai key and endpoint\n",
        "# cocoon_llm_setting['api_key'] = \"...\"\n",
        "# cocoon_llm_setting['api_base'] = \"https://xxx.openai.azure.com/\"\n",
        "# # deployed model in azure openai\n",
        "# cocoon_llm_setting['api_version'] = \"2023-12-01-preview\"\n",
        "# cocoon_llm_setting['azure_engine'] = \"xxx\"\n",
        "\n",
        "# test if LLM works\n",
        "test_message = \"hello\"\n",
        "messages = [{\"role\": \"user\", \"content\": test_message}]\n",
        "response = call_llm_chat(messages, temperature=0.1, top_p=0.1, use_cache=False)\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build DBT Lineage by LLMs\n",
        "dbt_directory = os.path.join(\".\", project_name)\n",
        "main_workflow = create_cocoon_dbt_explore_workflow(nodes=nodes, edges=edges, sql_mapping=sql_mapping, column_mapping=column_mapping, viewer=True)\n",
        "main_workflow.start()"
      ],
      "metadata": {
        "id": "5HYuwzsrF2Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the result to disk\n",
        "main_workflow.para['dbt_lineage'].save_to_disk(db_name=os.path.join(dbt_directory, \"cocoon_lineage.db\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaX1nU1HIDNB",
        "outputId": "af4a2d2c-de78-48ac-ce09-07b05453e3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database saved to ./dbt_amplitude/cocoon_lineage.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the result from disk\n",
        "dbt_lineage = DbtLineage(db_name=os.path.join(dbt_directory, \"cocoon_lineage.db\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OPcWn9DIPqz",
        "outputId": "a1ad7d63-5415-4f83-beff-babb5321af2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database imported from ./dbt_amplitude/cocoon_lineage.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display the Table Lineage\n",
        "dbt_lineage.interactive_lineage_display()"
      ],
      "metadata": {
        "id": "7EEqET4PJA23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display the Column Lineage\n",
        "# dbt_lineage.display_column_lineage(model_name=\"model.amplitude.amplitude__daily_performance\", column_name=\"event_day\")\n",
        "dbt_lineage.display_column_lineage(model_name=\"model.amplitude.amplitude__daily_performance\", column_name=\"number_users\")"
      ],
      "metadata": {
        "id": "wTOP1CHTJEBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write the whole lineage report to an html\n",
        "project_name = \"dbt_amplitude\"\n",
        "html_content = dbt_lineage.to_html(dbt_name=project_name)\n",
        "with open(f'{project_name}.html', 'w') as f:\n",
        "    f.write(html_content)"
      ],
      "metadata": {
        "id": "YOucF9YrQrzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}