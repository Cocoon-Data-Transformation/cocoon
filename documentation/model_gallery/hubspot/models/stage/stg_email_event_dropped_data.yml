version: 2
models:
- name: stg_email_event_dropped_data
  description: The table is about dropped email events. It contains details of each
    dropped email, including a unique ID, the reason for dropping, encrypted recipient
    and sender information, and an encrypted subject line. The drop reasons include
    "PREVIOUSLY_UNSUBSCRIBED_PORTAL" and "PREVIOUSLY_BOUNCED", indicating why the
    emails were not delivered.
  columns:
  - name: drop_reason
    description: Reason for email being dropped
    tests:
    - not_null
    - accepted_values:
        values:
        - PREVIOUSLY_BOUNCED
        - PREVIOUSLY_UNSUBSCRIBED_PORTAL
        - PREVIOUSLY_UNSUBSCRIBED_MESSAGE
        - INVALID_TO_ADDRESS
        - PREVIOUS_SPAM
        - DOMAIN_BLOCK
        - IP_BLOCK
        - SUPPRESSION_LIST
        - INVALID_SENDER
        - CONTENT_FILTERED
        - RATE_LIMITED
        - ATTACHMENT_BLOCKED
        - SIZE_LIMIT_EXCEEDED
  - name: encrypted_bcc
    description: Encrypted blind carbon copy recipient(s)
    tests:
    - not_null
  - name: encrypted_cc
    description: Encrypted carbon copy recipient(s)
    tests:
    - not_null
  - name: encrypted_drop_message
    description: Encrypted message about why email was dropped
    tests:
    - not_null
  - name: encrypted_sender
    description: Encrypted sender email address
    tests:
    - not_null
  - name: encrypted_reply_to
    description: Encrypted reply-to email address
    tests:
    - not_null
  - name: encrypted_subject
    description: Encrypted subject line of the email
    tests:
    - not_null
  - name: event_id
    description: Unique identifier for the dropped email event
    tests:
    - not_null
    - unique
    cocoon_meta:
      uniqueness: This column contains a unique identifier for each dropped email
        event. For this table, each row represents a distinct dropped email event.
        The event_id appears to be a UUID (Universally Unique Identifier), which is
        designed to be unique across all instances. It is highly unlikely to have
        duplicate values, even in a very large dataset.
